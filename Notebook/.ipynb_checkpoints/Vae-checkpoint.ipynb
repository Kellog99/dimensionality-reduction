{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bac26a0-608c-4f20-a5db-5b33cce02265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### general package ####\n",
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "#### model package ####\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e75153c-2926-4a6b-b644-f508f921eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data = \"MNIST\"\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 256\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Grayscale(),\n",
    "                                transforms.Resize((64,64), antialias=True),\n",
    "                                transforms.Normalize((0), (0.2))])\n",
    "config['model'][\"dataset\"] = data \n",
    "\n",
    "train_dataset = getattr(datasets, data)(root='../data', train=True, download=True, transform= transform)\n",
    "test_dataset = getattr(datasets, data)(root='../data', train=False, download=True, transform= transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "input_feat = len(train_dataset[0][0].flatten(0))\n",
    "batch, _ = next(iter(train_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d87180-0be2-48e1-b727-5fbd0d85c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(loss_train: list, \n",
    "         loss_val: list, \n",
    "         model, \n",
    "         ds, \n",
    "         config: yaml, \n",
    "         transform: None, \n",
    "         pieces_of_loss_train:dict = None,\n",
    "         pieces_of_loss_val:dict = None):\n",
    "    if type(ds.targets) == list:\n",
    "        targets = torch.tensor(ds.targets).unique()\n",
    "    else:\n",
    "        targets = ds.targets.unique()\n",
    "    n_images = np.min([config['plot']['n_images'], len(targets)])\n",
    "    targets = targets[:n_images]\n",
    "    dataset = config['model']['dataset']             \n",
    "    show_pieces = config['plot']['show_pieces']\n",
    "    show_rec = config['plot']['show_rec']\n",
    "    show_training = config['plot']['show_training']\n",
    "    model_type = {\n",
    "        1: \"auto\",\n",
    "        2: \"vae\",\n",
    "        3: \"vae_recurrent\"\n",
    "    }\n",
    "    model_type = model_type[config['model']['model']]\n",
    "        \n",
    "    l = {'epoch' :range(1, len(loss_train)+1),\n",
    "         'training':loss_train, \n",
    "         'validation':loss_val}\n",
    "    fig = px.line(l, \n",
    "                  x ='epoch', \n",
    "                  y=['training','validation'],\n",
    "                  title = \"Loss of the training\",\n",
    "                  width = 700, \n",
    "                  height = 600)\n",
    "    if show_training:\n",
    "        fig.show()\n",
    "        \n",
    "\n",
    "    y = list(pieces_of_loss_train.keys())\n",
    "    y.remove('epoch')\n",
    "    fig = px.line(pieces_of_loss_train, \n",
    "                  x ='epoch', \n",
    "                  y= y,\n",
    "                  title = \"pieces of the training loss\",\n",
    "                  width = 800, \n",
    "                  height = 700)\n",
    "    \n",
    "    fig.write_html(os.path.join(config['paths']['images'],model_type, f'piece_train_{dataset}.html'))\n",
    "    if show_pieces:\n",
    "        fig.show()\n",
    "\n",
    "    fig = px.line(pieces_of_loss_val, \n",
    "                  x = 'epoch', \n",
    "                  y= y,\n",
    "                  title = \"pieces of the validation loss\",\n",
    "                  width = 800, \n",
    "                  height = 700)\n",
    "    \n",
    "    fig.write_html(os.path.join(config['paths']['images'],model_type, f'piece_val_{dataset}.html'))\n",
    "    if show_pieces:\n",
    "        fig.show()\n",
    "             \n",
    "    #reconstruction part\n",
    "\n",
    "    fig, axes = plt.subplots(nrows = n_images, \n",
    "                             ncols = 2, \n",
    "                             figsize = (6, n_images*3),\n",
    "                             constrained_layout=True)\n",
    "    title = {\n",
    "        1: \"Autoencoder\",\n",
    "        2: \"Variational autoencoder\",\n",
    "        3: \"Vae Recurrent\"\n",
    "    }\n",
    "    title = title[config['model']['model']]\n",
    "\n",
    "    fig.suptitle(f\"{title} {model.hidden_dim}D for {dataset}\")\n",
    "    with torch.no_grad():\n",
    "        for i, target in enumerate(targets):\n",
    "            if type(ds.targets) == list:\n",
    "                data = ds.data[[True if x == i else False for x in ds.targets]][0]\n",
    "            else:\n",
    "                data = ds.data[ds.targets==target][0].numpy()\n",
    "\n",
    "            data = transform(data)[0]\n",
    "            data = data.unsqueeze(0) if len(data.shape) == 2 else data\n",
    "\n",
    "            if config['model']['model'] in [2,3]: \n",
    "                recon, _, _, _,_ = model(data.float().to(model.device))\n",
    "            else:\n",
    "                recon = model.cpu()(data.float().flatten(1))\n",
    "            axes[i,0].imshow(data[0], cmap = 'gray')\n",
    "            axes[i,1].imshow(recon.detach().cpu().numpy().reshape(data.shape[1:]), cmap = 'gray')\n",
    "        \n",
    "            axes[i,0].set_title(\"real\")\n",
    "            axes[i,1].set_title(\"reconstructed\")\n",
    "    plt.savefig(os.path.join(config['paths']['images'],model_type, f'rec_{model.hidden_dim}D_{dataset}.png'))    \n",
    "    if show_rec:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15022b-fa1f-40b9-b5d6-2d76ab1b2be9",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33732ee3-5ab7-442e-8a1b-5245d9341312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dist_fun(nn.Module):\n",
    "    def __init__(self,\n",
    "                 inverse: bool, \n",
    "                 hidden_dim:int = 64):\n",
    "        super(dist_fun, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.inverse = inverse\n",
    "        # Encoder layers        \n",
    "        fc1 = [nn.Linear(1, hidden_dim), \n",
    "               nn.Sigmoid(), \n",
    "               nn.Linear(hidden_dim, 1)]\n",
    "\n",
    "        self.fc1 = nn.Sequential(*fc1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "        \n",
    "    def derivative(self, y, x):\n",
    "        derivative = torch.autograd.grad(y, x, \n",
    "                                       grad_outputs = torch.ones_like(x),\n",
    "                                       create_graph = True, \n",
    "                                       retain_graph = True)[0]\n",
    "        return derivative\n",
    "\n",
    "# Define VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_feat: int,\n",
    "                 criterium,\n",
    "                 device, \n",
    "                 hidden_dim: int):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder layers\n",
    "        self.criterium = criterium\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        self.input_feat = input_feat\n",
    "        self.upper_bound_var = torch.tensor([5.]*hidden_dim, device = device, requires_grad = True).float()\n",
    "        self.fc1 = nn.Sequential(nn.Flatten(1),\n",
    "                                 nn.Linear(input_feat, 512),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(512, 256))\n",
    "        \n",
    "        self.fc_mu = nn.Sequential(nn.Linear(256, 128),\n",
    "                                   nn.Tanh(),\n",
    "                                   nn.Linear(128, hidden_dim))\n",
    "        \n",
    "        self.fc_logvar = nn.Sequential(nn.Linear(256, 128),\n",
    "                                       nn.Tanh(),\n",
    "                                       nn.Linear(128, hidden_dim))\n",
    "\n",
    "        # Decoder layers\n",
    "        \n",
    "        self.fc2 = nn.Sequential(nn.Linear(hidden_dim, 128),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(128, 256),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(256, 512),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(512, input_feat))\n",
    "\n",
    "        #### F^{-1}(u) ####\n",
    "        self.F_inv = dist_fun(inverse = True)\n",
    "\n",
    "        #### F(F^{-1}(u)) ####\n",
    "        self.F = dist_fun(inverse = False)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mu = self.fc_mu(x)\n",
    "        log_var = self.fc_logvar(x)\n",
    "        log_var = torch.max(torch.min(log_var,torch.ones_like(log_var)*4),torch.ones_like(log_var)*(-4)) \n",
    "        var = torch.exp(log_var)\n",
    "        return mu, var#.view(-1,self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.fc2(z)\n",
    "\n",
    "        \n",
    "    def reparameterize(self, mu, var):\n",
    "\n",
    "        #### Generating the random distribution #####\n",
    "        u = torch.rand_like(mu, requires_grad = True).float().view(-1,1)\n",
    "        x = self.F_inv(u)\n",
    "        u_hat = self.F(x)\n",
    "        \n",
    "        ### Perturbing the embedding \n",
    "        z = mu + var*x.view(-1,self.hidden_dim)#torch.bmm(var,x.view(-1,self.hidden_dim, 1)).view(-1, self.hidden_dim)\n",
    "        return z, u, u_hat, x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, var = self.encode(x.view(-1, self.input_feat))\n",
    "        z, u, u_hat, x, = self.reparameterize(mu, var)\n",
    "        x_reconstructed = self.decode(z)\n",
    "        \n",
    "        return x_reconstructed, u, x, u_hat, var\n",
    "    \n",
    "    \n",
    "    def loss_density(self):\n",
    "        u = torch.rand(500, requires_grad = True).view(-1,1).float().to(self.device)\n",
    "        X = self.F_inv(u)\n",
    "\n",
    "        ### Voglio che mu = 0 e std = 1\n",
    "        mean = torch.abs(torch.mean(X))\n",
    "        std = torch.mean(X**2)\n",
    "\n",
    "        #### proprietà densità\n",
    "        x = torch.tensor([-30.], requires_grad = True).float().to(self.device)\n",
    "        lower = self.F(x)[0]\n",
    "        upper = self.F(-x)[0]\n",
    "\n",
    "        domain = torch.linspace(-20, 20, \n",
    "                               steps = 500, \n",
    "                               requires_grad = True).view(-1,1).float().to(self.device)     ## positività\n",
    "        \n",
    "        y = self.F(domain.requires_grad_())\n",
    "        \n",
    "        density = self.F.derivative(y,domain)\n",
    "        p = torch.sum(density)\n",
    "        positivity = torch.sum(F.relu(-density))      # f(x)>= 0\n",
    "        ####### Constraints della distribuzione \n",
    "        one = torch.tensor(1.).to(self.device)\n",
    "        # media 0\n",
    "        l = mean\n",
    "        # varianza 1\n",
    "        std_loss = self.criterium(std, one)\n",
    "        # upper = 1 ==> F(infty)=1\n",
    "        upper_loss = self.criterium(upper, one)\n",
    "        #lower = 0 ==> F(-infty)= 0\n",
    "        lower_loss = torch.sum(lower)\n",
    "        # int f(x)dx = 1\n",
    "        normality = self.criterium(p, one)\n",
    "\n",
    "        l = mean + std_loss + upper_loss + lower_loss + positivity + normality\n",
    "        \n",
    "        return l, (mean.item(), std_loss.item(), upper_loss.item(), lower_loss.item(), positivity.item(), normality.item())\n",
    "\n",
    "    def loss_functional(self, img, img_rec, u, x, u_hat, var):\n",
    "        density1 = self.F_inv.derivative(x, u)\n",
    "        density2 = self.F.derivative(u_hat, x)\n",
    "\n",
    "        l = 0\n",
    "    \n",
    "        #### chain rule\n",
    "        identity = self.criterium(density1, 1/density2)\n",
    "        ### reconstruction loss for distribution\n",
    "        reconstruction1 =  self.criterium(u, u_hat)\n",
    "        ### reconstruction loss for image\n",
    "        reconstruction2 = self.criterium(img, img_rec)\n",
    "        ### Kullenback Leiberg divergence\n",
    "\n",
    "        l = identity + reconstruction1 + 500*reconstruction2\n",
    "        \n",
    "        kl = torch.mean(torch.log(density2[density2>0]))\n",
    "        #logA = torch.mean(torch.log(torch.linalg.det(var)))\n",
    "        det_var = torch.prod(var,1)\n",
    "        if torch.any(det_var<0):\n",
    "            print(\"det negativo\")\n",
    "        logA = torch.mean(torch.log(det_var))\n",
    "        if torch.any(torch.isnan(kl)) or torch.any(torch.isnan(logA)):\n",
    "            kl = torch.tensor(0, device = self.device).float()\n",
    "        else:\n",
    "            kl = logA-kl\n",
    "        l += kl\n",
    "        l += 1/torch.mean(det_var)\n",
    "        return l, (identity.item(), reconstruction1.item(), reconstruction2.item(), kl.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04e5f0c-5804-4886-b950-6f875d6ab097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(model, \n",
    "         dataloader,\n",
    "         optimizer,\n",
    "         pieces_of_loss: dict, \n",
    "         training: bool = False):\n",
    "    loss_epoch = 0.0\n",
    "    len_load = len(dataloader)\n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    for data, _ in iter(dataloader):\n",
    "        # blocking the gradient summation \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward step\n",
    "        x_reconstructed, u, x, u_hat, var  = model(data.to(model.device).float())\n",
    "        \n",
    "        # computing the loss\n",
    "        l1, dens = model.loss_density()\n",
    "        l2, func = model.loss_functional(data.to(model.device).flatten(1).float(), x_reconstructed, u, x, u_hat, var)\n",
    "        loss = l1 + l2 \n",
    "        \n",
    "        pieces = dens + func\n",
    "        if torch.any(torch.isnan(loss)).item():\n",
    "            print(dens)\n",
    "            print(func)\n",
    "        # Backward and optimize\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_epoch += loss.item()\n",
    "        for i, key in enumerate(pieces_of_loss.keys()):\n",
    "            if 'std_emb' == key:\n",
    "                pieces_of_loss[key][-1] += torch.mean(torch.prod(var,1)).item()/len_load\n",
    "            else:\n",
    "                pieces_of_loss[key][-1] += pieces[i]/len_load\n",
    "    return loss_epoch/len_load\n",
    "\n",
    "def training(model, \n",
    "             train_loader, \n",
    "             val_loader, \n",
    "             num_epochs,\n",
    "             optimizer):\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    be = np.inf\n",
    "    bm = model\n",
    "    \n",
    "    pieces_of_loss_train = {'mean':[], 'std_loss':[], 'upper_loss':[], 'positivity':[], 'normality':[], 'identity':[], 'reconstruction1':[], 'reconstruction2':[], 'kl_loss':[], 'std_emb':[]}    \n",
    "    pieces_of_loss_val = {'mean':[], 'std_loss':[], 'upper_loss':[], 'positivity':[], 'normality':[], 'identity':[], 'reconstruction1':[], 'reconstruction2':[], 'kl_loss':[], 'std_emb':[]}    \n",
    "    model.train()\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):    \n",
    "        for key in pieces_of_loss_train.keys():\n",
    "            pieces_of_loss_train[key].append(0)\n",
    "            pieces_of_loss_val[key].append(0)\n",
    "        l = step(model, train_loader, optimizer, pieces_of_loss_train, True)\n",
    "        loss_train.append(l)\n",
    "\n",
    "        l = step(model, val_loader, optimizer,pieces_of_loss_val)\n",
    "        loss_val.append(l)\n",
    "        \n",
    "        if (epoch+1)%5==0:\n",
    "            print(f\"loss training at the {epoch+1}-th = {loss_train[-1]}\")\n",
    "            print(f\"loss validation at the {epoch+1}-th = {loss_val[-1]}\")\n",
    "            \n",
    "        if loss_val[-1]<be:\n",
    "            be = loss_val[-1]\n",
    "            bm = model\n",
    "    pieces_of_loss_train['epoch'] = list(range(1, num_epochs+1))\n",
    "    pieces_of_loss_val['epoch'] = list(range(1, num_epochs+1))\n",
    "    return bm, loss_train, loss_val, pieces_of_loss_train, pieces_of_loss_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff6b293e-0c9a-48ca-8c29-9de8dad1ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linfty(y, yh):\n",
    "    diff = torch.sum(torch.abs(y.to(device)-yh).max(0)[0])\n",
    "    mse = F.mse_loss(y,yh)\n",
    "    return diff + 10*mse\n",
    "    \n",
    "model = VAE(input_feat= input_feat, \n",
    "            hidden_dim = config['model']['hidden_dimension'], \n",
    "            device = device, \n",
    "            criterium = linfty).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482840df-5735-4713-9df9-2fcdfa070a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Training the vae\n",
    "model, loss_train, loss_val, piece_train, piece_val = training(model = model, \n",
    "                                                                train_loader = train_loader, \n",
    "                                                                val_loader = test_loader, \n",
    "                                                                num_epochs = 50, #config['optimizer']['epochs'], \n",
    "                                                                optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637eaf4-fc3f-421e-8ed1-83340313d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_val, \n",
    "            loss_val, \n",
    "            model, \n",
    "            ds = train_dataset, \n",
    "            config=config,\n",
    "            transform= transform ,\n",
    "            pieces_of_loss_train = piece_val, \n",
    "            pieces_of_loss_val = piece_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
